{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression_chicken.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "fs7LH5Q5dUV_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax-DCn8-c9xI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  \n",
        "import numpy as np  \n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as seabornInstance \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LogisticRegression # import logistic regression\n",
        "from sklearn import metrics\n",
        "from vega_datasets import data\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "r0abBW-kdkta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload dataset"
      ],
      "metadata": {
        "id": "KvhfBCrsdpwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('FILE_PATH.csv')\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "PvEqidB9drjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## # Divide the data into attributes and labels"
      ],
      "metadata": {
        "id": "eVoxey2bd1-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset[['head_x', \n",
        "             'head_y', \n",
        "             'neck_x', \n",
        "             'neck_y', \n",
        "             'body_x', \n",
        "             'body_y', \n",
        "             'tail_x', \n",
        "             'tail_y', \n",
        "             'leg_r_x', \n",
        "             'leg_r_y', \n",
        "             'leg_l_x', \n",
        "             'leg_l_y', \n",
        "             'width', \n",
        "             'length', \n",
        "             'r_x',\n",
        "             'r_y',\n",
        "            ]].values\n",
        "y = dataset['class'].values"
      ],
      "metadata": {
        "id": "0PBjEQ-Cd4GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.tight_layout()\n",
        "seabornInstance.distplot(dataset['class'])"
      ],
      "metadata": {
        "id": "Q0485BnMd95Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the dataset to train and test"
      ],
      "metadata": {
        "id": "OROSJvANeFmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide the data into training and testing partition \n",
        "# train => 70%\n",
        "# test => 30%\n",
        "# we use the following function that we imported above:\n",
        "# from sklearn.model_selection import train_test_split \n",
        "\n",
        "print(f'X : {X.shape}, y : {y.shape}')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "print (f'X_train: {X_train.shape}')\n",
        "print (f'X_test: {X_test.shape}')\n",
        "\n",
        "print (f'y_train: {y_train.shape}')\n",
        "print (f'y_test: {y_test.shape}')"
      ],
      "metadata": {
        "id": "CXzG1-igeAt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Before Normalization: ')\n",
        "print(f'Train: max {X_train.max(axis=0)}, min {X_train.min(axis=0)}')\n",
        "print(f'Test: max {X_test.max(axis=0)}, min {X_test.min(axis=0)}')\n",
        "\n",
        "#Calculate mean and std for the training data. \n",
        "train_mean = X_train.mean(axis=0)\n",
        "train_std = X_train.std(axis=0)\n",
        "\n",
        "# normalize train and test data\n",
        "X_train_nrom = (X_train - train_mean) / train_std\n",
        "X_test_nrom = (X_test - train_mean) / train_std\n",
        "\n",
        "print('*' * 20)\n",
        "print('After Normalization: ')\n",
        "print(f'Train: max {X_train_nrom.max(axis=0)}, min {X_train_nrom.min(axis=0)}')\n",
        "print(f'Test: max {X_test_nrom.max(axis=0)}, min {X_test_nrom.min(axis=0)}')"
      ],
      "metadata": {
        "id": "tUrc3cGheOU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "jGmAsfSqeXgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = LogisticRegression(solver='liblinear', max_iter=1000)  # solver='liblinear' for one-versus-rest \n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vsRteIc3eS4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model and calculate the accuracy"
      ],
      "metadata": {
        "id": "mN-_YcZaeKr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_train)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_train, y_pred))\n",
        "\n",
        "df = pd.DataFrame({'Actual': y_train, 'Predicted': y_pred})\n",
        "df1 = df.head(20)\n",
        "df1"
      ],
      "metadata": {
        "id": "tC-Rmj6yeb-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test data accuracy"
      ],
      "metadata": {
        "id": "zF-zz6JHerio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df1 = df.head(20)\n",
        "df1"
      ],
      "metadata": {
        "id": "lAbFWKanesqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot prediction versus actual "
      ],
      "metadata": {
        "id": "gYkf0vFafAWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.plot(kind='bar',figsize=(20,8))\n",
        "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
        "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p3a2wOIkezah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix"
      ],
      "metadata": {
        "id": "rB46RYZIe7Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "class_names=[0,1] # name  of classes\n",
        "fig, ax = plt.subplots()\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "# create heatmap\n",
        "seabornInstance.heatmap(pd.DataFrame(cm), annot=True, cmap='Blues' ,fmt='g')\n",
        "#ax.xaxis.set_label_position(\"top\")\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion Matrix') #, y=1.1)\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "ax.xaxis.set_ticklabels(['Positive', 'Negative']); ax.yaxis.set_ticklabels(['Positive', 'Negative']);"
      ],
      "metadata": {
        "id": "dlPu2us6e4mH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}